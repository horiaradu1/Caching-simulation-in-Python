{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Caching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we begin with importing everything we need and creating the test values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from memory import Memory, CyclicCache, LRUCache, RandomCache\n",
    "from random import randint\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments\n",
    "\n",
    "Below we create the test data and set the max size of every cache"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Size of the cache\n",
    "cache_size = 4# |Changeable|\n",
    "\n",
    "# Test data for the different types of caches\n",
    "test_data_size = 1000 # |Changeable|\n",
    "test_data_range = 9 # |Changeable|\n",
    "test_data = [randint(1, test_data_range) for i in range(test_data_size)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This will test for cache sizes from 1 to our cache size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = {\"Memory\":[], \"Cyclic\":[], \"LRU\":[], \"Random\":[]}\n",
    "for size in tqdm.tqdm(range (1, cache_size + 1)):\n",
    "    \n",
    "    mem = Memory()\n",
    "    cyclic = CyclicCache(size)\n",
    "    lru = LRUCache(size)\n",
    "    rand = RandomCache(size)\n",
    "    \n",
    "    for datum in test_data:\n",
    "        mem.lookup(datum)\n",
    "    data[\"Memory\"].append(mem.get_hit_count())\n",
    "    \n",
    "    for datum in test_data:\n",
    "        cyclic.lookup(datum)\n",
    "    data[\"Cyclic\"].append(cyclic.get_hit_count())\n",
    "\n",
    "    for datum in test_data:\n",
    "        lru.lookup(datum)\n",
    "    data[\"LRU\"].append(lru.get_hit_count())\n",
    "\n",
    "    for datum in test_data:\n",
    "        rand.lookup(datum)\n",
    "    data[\"Random\"].append(rand.get_hit_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "### We print each hit count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Memory \" + str(mem.get_hit_count()) + \" Hits\")\n",
    "\n",
    "print(\"Cyclic \" + str(cyclic.get_hit_count()) + \" Hits\")\n",
    "\n",
    "print(\"LRU    \" + str(lru.get_hit_count()) + \" Hits\")\n",
    "\n",
    "print(\"Random \" + str(rand.get_hit_count()) + \" Hits\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### Then we try to display the data so as to see any possible differences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(20,15))\n",
    "ax = figure.gca()\n",
    "df = pd.DataFrame(data = data)\n",
    "df.plot(kind = \"line\", ax = ax, y = \"Memory\", c = \"red\")\n",
    "df.plot(kind = \"line\", ax = ax, y = \"Cyclic\", c = \"black\")\n",
    "df.plot(kind = \"line\", ax = ax, y = \"LRU\", c = \"blue\")\n",
    "df.plot(kind = \"line\", ax = ax, y = \"Random\", c = \"green\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diff2 = pd.DataFrame({'Cache Type':['Cyclic', 'LRU', 'Random'], 'Hit Counts':[cyclic.get_hit_count(), lru.get_hit_count(), rand.get_hit_count()]})\n",
    "ax = diff2.plot.bar(x='Cache Type', y='Hit Counts', rot=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "##### Seeing as apart from the Memory, where it has as many hit counts as the test data size itself, we get a similar result for the other 3, we try and change the testing values and data to see if we can spot anything else."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cache_size = 4\n",
    "test_data_size = 50000\n",
    "test_data_range = 9\n",
    "test_data = [randint(1, test_data_range) for i in range(test_data_size)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = {\"Memory\":[], \"Cyclic\":[], \"LRU\":[], \"Random\":[]}\n",
    "\n",
    "mem = Memory()\n",
    "cyclic = CyclicCache(cache_size)\n",
    "lru = LRUCache(cache_size)\n",
    "rand = RandomCache(cache_size)\n",
    "\n",
    "for datum in test_data:\n",
    "    mem.lookup(datum)\n",
    "data[\"Memory\"].append(mem.get_hit_count())\n",
    "\n",
    "for datum in test_data:\n",
    "    cyclic.lookup(datum)\n",
    "data[\"Cyclic\"].append(cyclic.get_hit_count())\n",
    "\n",
    "for datum in test_data:\n",
    "    lru.lookup(datum)\n",
    "data[\"LRU\"].append(lru.get_hit_count())\n",
    "\n",
    "for datum in test_data:\n",
    "    rand.lookup(datum)\n",
    "data[\"Random\"].append(rand.get_hit_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Memory       has \" + str(mem.get_hit_count()) + \" Hits\")\n",
    "print(\"Cyclic Cache has \" + str(cyclic.get_hit_count()) + \" Hits\")\n",
    "print(\"LRU    Cache has \" + str(lru.get_hit_count()) + \" Hits\")\n",
    "print(\"Random Cache has \" + str(rand.get_hit_count()) + \" Hits\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Here we notice that the Cyclic and LRU Caches memory hits tend to be similar, with only small differences, but the Random Cache will start varying more as the test data gets bigger.\n",
    "##### (Could not start testing higher values as my computer could not keep up)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "#### Below we will test a theory about the correlation between the cache size and the range an address can take a value from"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cache_size = 10\n",
    "test_data_size = 10000\n",
    "test_data_range = 20\n",
    "test_data = [randint(1, test_data_range) for i in range(test_data_size)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = {\"Memory\":[], \"Cyclic\":[], \"LRU\":[], \"Random\":[]}\n",
    "\n",
    "mem = Memory()\n",
    "cyclic = CyclicCache(cache_size)\n",
    "lru = LRUCache(cache_size)\n",
    "rand = RandomCache(cache_size)\n",
    "\n",
    "for datum in test_data:\n",
    "    mem.lookup(datum)\n",
    "data[\"Memory\"].append(mem.get_hit_count())\n",
    "\n",
    "for datum in test_data:\n",
    "    cyclic.lookup(datum)\n",
    "data[\"Cyclic\"].append(cyclic.get_hit_count())\n",
    "\n",
    "for datum in test_data:\n",
    "    lru.lookup(datum)\n",
    "data[\"LRU\"].append(lru.get_hit_count())\n",
    "\n",
    "for datum in test_data:\n",
    "    rand.lookup(datum)\n",
    "data[\"Random\"].append(rand.get_hit_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Memory       has \" + str(mem.get_hit_count()) + \" Hits\")\n",
    "print(\"Cyclic Cache has \" + str(cyclic.get_hit_count()) + \" Hits\")\n",
    "print(\"LRU    Cache has \" + str(lru.get_hit_count()) + \" Hits\")\n",
    "print(\"Random Cache has \" + str(rand.get_hit_count()) + \" Hits\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Our theory was proven, meaning that the number of memory access in the caches depends on the size of the cache and test data address range\n",
    "##### Here, a lookup will result in a memory access approximately (10 divided by 20)%, that means 50%, which would seem true."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Conclusions\n",
    "\n",
    "All three of the caches would typically yield a very similar amount of memory accesses, with a possibility of them to differ more when the data was bigger\n",
    "\n",
    "* How often does a lookup result in memory access?\n",
    "\n",
    " A lookup resulting in a memory access depends on what test values and data we will take.\n",
    " From what I have seen, the percentage will approximately be the size of the cache divided by how many possible addresses/address_range we've got.\n",
    " (cache_size/test_data_range)\n",
    "\n",
    "* Are there differences between the behaviour of the strategies?\n",
    "\n",
    " All in all, the strategies tend to have an approximately equal answer, without the possibility to pinpoint an exact difference due to the similar result they gave."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}